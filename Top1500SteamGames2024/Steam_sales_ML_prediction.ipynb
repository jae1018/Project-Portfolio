{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e44ebe",
   "metadata": {},
   "source": [
    "# Top 1500 Steam Sales (2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f9fcf",
   "metadata": {},
   "source": [
    "In this notebook, we're going to try to predict the publisherClass of every game using only the revenue, price, and average playtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53832abc",
   "metadata": {},
   "source": [
    "First off, libraries as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a792fb6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/python_ML/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import check_random_state\n",
    "import warnings\n",
    "\n",
    "# for generating synthetic data for minitority classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a79af5",
   "metadata": {},
   "source": [
    "Let's set a seed first for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be990a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    check_random_state(seed)\n",
    "\n",
    "# Set seed\n",
    "rng_seed = 0\n",
    "set_seed(rng_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b00b861",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9fead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_revenue = pd.read_csv('steam_revenue_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb307c94",
   "metadata": {},
   "source": [
    "Confirm that the data loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95868c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>copiesSold</th>\n",
       "      <th>price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>avgPlaytime</th>\n",
       "      <th>reviewScore</th>\n",
       "      <th>publisherClass</th>\n",
       "      <th>publishers</th>\n",
       "      <th>developers</th>\n",
       "      <th>steamId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WWE 2K24</td>\n",
       "      <td>07-03-2024</td>\n",
       "      <td>165301</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8055097.0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2K</td>\n",
       "      <td>Visual Concepts</td>\n",
       "      <td>2315690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EARTH DEFENSE FORCE 6</td>\n",
       "      <td>25-07-2024</td>\n",
       "      <td>159806</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7882151.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Indie</td>\n",
       "      <td>D3PUBLISHER</td>\n",
       "      <td>SANDLOT</td>\n",
       "      <td>2291060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sins of a Solar Empire II</td>\n",
       "      <td>15-08-2024</td>\n",
       "      <td>214192</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7815247.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Stardock Entertainment</td>\n",
       "      <td>Ironclad Games Corporation,Stardock Entertainment</td>\n",
       "      <td>1575940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legend of Mortal</td>\n",
       "      <td>14-06-2024</td>\n",
       "      <td>440998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7756399.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Paras Games,Obb Studio Inc.</td>\n",
       "      <td>Obb Studio Inc.</td>\n",
       "      <td>1859910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shin Megami Tensei V: Vengeance</td>\n",
       "      <td>13-06-2024</td>\n",
       "      <td>141306</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7629252.0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>SEGA</td>\n",
       "      <td>ATLUS</td>\n",
       "      <td>1875830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name releaseDate  copiesSold  price    revenue   \n",
       "0                         WWE 2K24  07-03-2024      165301  100.0  8055097.0  \\\n",
       "1            EARTH DEFENSE FORCE 6  25-07-2024      159806   60.0  7882151.0   \n",
       "2        Sins of a Solar Empire II  15-08-2024      214192   50.0  7815247.0   \n",
       "3                 Legend of Mortal  14-06-2024      440998   20.0  7756399.0   \n",
       "4  Shin Megami Tensei V: Vengeance  13-06-2024      141306   60.0  7629252.0   \n",
       "\n",
       "   avgPlaytime  reviewScore publisherClass                   publishers   \n",
       "0         42.4         71.0            AAA                           2K  \\\n",
       "1         29.7         57.0          Indie                  D3PUBLISHER   \n",
       "2         12.5         88.0          Indie       Stardock Entertainment   \n",
       "3         24.8         76.0          Indie  Paras Games,Obb Studio Inc.   \n",
       "4         34.3         96.0             AA                         SEGA   \n",
       "\n",
       "                                          developers  steamId  \n",
       "0                                    Visual Concepts  2315690  \n",
       "1                                            SANDLOT  2291060  \n",
       "2  Ironclad Games Corporation,Stardock Entertainment  1575940  \n",
       "3                                    Obb Studio Inc.  1859910  \n",
       "4                                              ATLUS  1875830  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_revenue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d1107",
   "metadata": {},
   "source": [
    "Prepare columns (input X and output y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14703cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and the target variable\n",
    "X = steam_revenue[['price', 'revenue', 'avgPlaytime']]\n",
    "y = steam_revenue['publisherClass']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4565a",
   "metadata": {},
   "source": [
    "Do train / test split - Note that there's no attempt to account for minority classes here (where we have about 1300 Indie, 150 AA, and 50 AAA), which will **absolutely** mess up recall!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ab6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rng_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d3a25e",
   "metadata": {},
   "source": [
    "Put all models into one giant function to call (with relevant train / test tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b5ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make big function returning fitted models\n",
    "def train_models(train_tuple, train_tuple_scaled, \n",
    "                 test_tuple, test_tuple_scaled):\n",
    "    \n",
    "    train_dat_x, train_dat_y = train_tuple\n",
    "    train_dat_scaled_x, train_dat_scaled_y = train_tuple_scaled\n",
    "    test_dat_x, test_dat_y = test_tuple\n",
    "    test_dat_scaled_x, test_dat_scaled_y = test_tuple_scaled\n",
    "    \n",
    "    model_types = ['log_reg', 'naive_bayes', 'rf', 'svc', 'knn', 'ens']\n",
    "    model = { elem : None for elem in model_types }\n",
    "    model_test_preds = { elem : None for elem in model_types }\n",
    "    model_test_acc = { elem : None for elem in model_types }\n",
    "    model_classif_report = { elem : None for elem in model_types }\n",
    "    \n",
    "    # log reg and gaussian nb\n",
    "    for key in ['log_reg','naive_bayes']:\n",
    "        model[key] = LogisticRegression() if key == 'log_reg' else GaussianNB()\n",
    "        model[key].fit(train_dat_x, train_dat_y)\n",
    "        model_test_preds[key] = model[key].predict(test_dat_x)\n",
    "        model_test_acc[key] = accuracy_score(test_dat_y, model_test_preds[key])\n",
    "        model_classif_report[key] = classification_report(test_dat_y, model_test_preds[key])\n",
    "        \n",
    "    \n",
    "    # rf\n",
    "    model['rf'] = RandomForestClassifier(random_state=rng_seed)\n",
    "    model['rf'].fit(train_dat_x, train_dat_y)\n",
    "    model_test_preds['rf'] = model['rf'].predict(test_dat_x)\n",
    "    model_test_acc['rf'] = accuracy_score(test_dat_y, model_test_preds['rf'])\n",
    "    model_classif_report['rf'] = classification_report(test_dat_y, model_test_preds['rf'])\n",
    "    \n",
    "    # svc\n",
    "    model['svc'] = SVC(kernel='linear', probability=True)\n",
    "    model['svc'].fit(train_dat_scaled_x, train_dat_scaled_y)\n",
    "    model_test_preds['svc'] = model['svc'].predict(test_dat_scaled_x)\n",
    "    model_test_acc['svc'] = accuracy_score(test_dat_scaled_y, model_test_preds['svc'])\n",
    "    model_classif_report['svc'] = classification_report(test_dat_scaled_y, model_test_preds['svc'])\n",
    "    \n",
    "    # knn\n",
    "    model['knn'] = KNeighborsClassifier(n_neighbors=5)\n",
    "    model['knn'].fit(train_dat_scaled_x, train_dat_scaled_y)\n",
    "    model_test_preds['knn'] = model['knn'].predict(test_dat_scaled_x)\n",
    "    model_test_acc['knn'] = accuracy_score(test_dat_scaled_y, model_test_preds['knn'])\n",
    "    model_classif_report['knn'] = classification_report(test_dat_scaled_y, model_test_preds['knn'])\n",
    "    \n",
    "    # ens\n",
    "    model['ens'] = VotingClassifier(estimators=[\n",
    "        ('rf',  model['rf']), \n",
    "        ('svc', model['svc']), \n",
    "        ('knn', model['knn'])], \n",
    "        voting='soft')  # Soft voting allows averaging probabilities\n",
    "    model['ens'].fit(train_dat_scaled_x, train_dat_scaled_y)\n",
    "    model_test_preds['ens'] = model['ens'].predict(test_dat_scaled_x)\n",
    "    model_test_acc['ens'] = accuracy_score(test_dat_scaled_y, model_test_preds['ens'])\n",
    "    model_classif_report['ens'] = classification_report(test_dat_scaled_y, model_test_preds['ens'])\n",
    "    \n",
    "    return model, model_test_preds, model_test_acc, model_classif_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ab919",
   "metadata": {},
   "source": [
    "Standardize original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2032940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features for models that benefit from normalization (SVC, KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82cb69",
   "metadata": {},
   "source": [
    "Make a tuple of the train / scaled train / test / scaled test sets (scaled for some of the ML models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffcafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuple = (X_train, y_train)\n",
    "train_tuple_scaled = (X_train_scaled, y_train)\n",
    "test_tuple = (X_test, y_test)\n",
    "test_tuple_scaled = (X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7672c13f",
   "metadata": {},
   "source": [
    "Train models with original dataset (expecting bad recall for AAA, possibly AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fde45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, model_test_preds, model_test_acc, model_classif_report = \\\n",
    "        train_models(train_tuple,\n",
    "                     train_tuple_scaled,\n",
    "                     test_tuple,\n",
    "                     test_tuple_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2e390",
   "metadata": {},
   "source": [
    "Now make a similar set of tuples but for the SMOTE-created dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b916d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 3) --- SMOTE INCREASED --> (3126, 3)\n"
     ]
    }
   ],
   "source": [
    "#init smote\n",
    "smote = SMOTE(random_state=rng_seed)\n",
    "# generate additional samples of minotrity classes from SMOTE\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print( X_train.shape,'--- SMOTE INCREASED -->',X_train_resampled.shape )\n",
    "\n",
    "# standardize for SMOTE\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# make tuples\n",
    "train_tuple_s = (X_train_resampled, y_train_resampled)\n",
    "train_tuple_scaled_s = (X_train_scaled, y_train_resampled)\n",
    "test_tuple_s = (X_test, y_test)\n",
    "test_tuple_scaled_s = (X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cb95b",
   "metadata": {},
   "source": [
    "Now train models again with SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721f8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_s, model_test_preds_s, model_test_acc_s, model_classif_report_s = \\\n",
    "        train_models(train_tuple_s,\n",
    "                     train_tuple_scaled_s,\n",
    "                     test_tuple_s,\n",
    "                     test_tuple_scaled_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a62f1568",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model log_reg:\n",
      "0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.57      0.15      0.24        27\n",
      "         AAA       0.00      0.00      0.00        14\n",
      "       Indie       0.88      0.99      0.93       259\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.48      0.38      0.39       300\n",
      "weighted avg       0.81      0.87      0.83       300\n",
      "\n",
      "++++++++++++++++++++++++++++\n",
      "For SMOTE model log_reg:\n",
      "0.04666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.00      0.00      0.00        27\n",
      "         AAA       0.05      1.00      0.09        14\n",
      "       Indie       0.00      0.00      0.00       259\n",
      "\n",
      "    accuracy                           0.05       300\n",
      "   macro avg       0.02      0.33      0.03       300\n",
      "weighted avg       0.00      0.05      0.00       300\n",
      "\n",
      "============================\n",
      "For model naive_bayes:\n",
      "0.8566666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.33      0.15      0.21        27\n",
      "         AAA       0.00      0.00      0.00        14\n",
      "       Indie       0.88      0.98      0.93       259\n",
      "\n",
      "    accuracy                           0.86       300\n",
      "   macro avg       0.40      0.37      0.38       300\n",
      "weighted avg       0.79      0.86      0.82       300\n",
      "\n",
      "++++++++++++++++++++++++++++\n",
      "For SMOTE model naive_bayes:\n",
      "0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.31      0.19      0.23        27\n",
      "         AAA       0.00      0.00      0.00        14\n",
      "       Indie       0.88      0.97      0.92       259\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.40      0.38      0.39       300\n",
      "weighted avg       0.79      0.85      0.82       300\n",
      "\n",
      "============================\n",
      "For model rf:\n",
      "0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.42      0.37      0.39        27\n",
      "         AAA       0.86      0.43      0.57        14\n",
      "       Indie       0.92      0.96      0.94       259\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.73      0.59      0.63       300\n",
      "weighted avg       0.87      0.88      0.87       300\n",
      "\n",
      "++++++++++++++++++++++++++++\n",
      "For SMOTE model rf:\n",
      "0.8033333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.29      0.44      0.35        27\n",
      "         AAA       0.27      0.43      0.33        14\n",
      "       Indie       0.94      0.86      0.90       259\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.50      0.58      0.53       300\n",
      "weighted avg       0.85      0.80      0.82       300\n",
      "\n",
      "============================\n",
      "For model svc:\n",
      "0.8733333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       1.00      0.11      0.20        27\n",
      "         AAA       0.00      0.00      0.00        14\n",
      "       Indie       0.87      1.00      0.93       259\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.62      0.37      0.38       300\n",
      "weighted avg       0.84      0.87      0.82       300\n",
      "\n",
      "++++++++++++++++++++++++++++\n",
      "For SMOTE model svc:\n",
      "0.7733333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.26      0.52      0.35        27\n",
      "         AAA       0.25      0.36      0.29        14\n",
      "       Indie       0.94      0.82      0.88       259\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.48      0.57      0.51       300\n",
      "weighted avg       0.85      0.77      0.80       300\n",
      "\n",
      "============================\n",
      "For model knn:\n",
      "0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.47      0.30      0.36        27\n",
      "         AAA       0.57      0.29      0.38        14\n",
      "       Indie       0.90      0.96      0.93       259\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.65      0.51      0.56       300\n",
      "weighted avg       0.85      0.87      0.85       300\n",
      "\n",
      "++++++++++++++++++++++++++++\n",
      "For SMOTE model knn:\n",
      "0.6833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.23      0.41      0.29        27\n",
      "         AAA       0.15      0.57      0.24        14\n",
      "       Indie       0.94      0.72      0.81       259\n",
      "\n",
      "    accuracy                           0.68       300\n",
      "   macro avg       0.44      0.57      0.45       300\n",
      "weighted avg       0.84      0.68      0.74       300\n",
      "\n",
      "============================\n",
      "For model ens:\n",
      "0.8833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.53      0.33      0.41        27\n",
      "         AAA       1.00      0.21      0.35        14\n",
      "       Indie       0.90      0.98      0.94       259\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.81      0.51      0.57       300\n",
      "weighted avg       0.87      0.88      0.86       300\n",
      "\n",
      "++++++++++++++++++++++++++++\n",
      "For SMOTE model ens:\n",
      "0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.29      0.37      0.32        27\n",
      "         AAA       0.23      0.50      0.32        14\n",
      "       Indie       0.95      0.86      0.90       259\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.49      0.58      0.51       300\n",
      "weighted avg       0.86      0.80      0.82       300\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for key in models:\n",
    "    \n",
    "    print(f'For model {key}:')\n",
    "    print(model_test_acc[key])\n",
    "    print(model_classif_report[key])\n",
    "    \n",
    "    print('++++++++++++++++++++++++++++')\n",
    "    \n",
    "    print(f'For SMOTE model {key}:')\n",
    "    print(model_test_acc_s[key])\n",
    "    print(model_classif_report_s[key])\n",
    "    \n",
    "    print('============================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
